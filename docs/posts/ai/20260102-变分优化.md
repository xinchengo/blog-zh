---
date: 2026-01-02
draft: true
---
# 变分优化

最近在学习[光流](20251215-Optical Flow.md)、[集成学习](20251223-AI3002 实验三记.md#集成学习)、[强化学习](20251229-强化学习.md)的过程中见到了很多“泛函”、“泛函优化”这些词；因此我打算自主探索一些变分相关的知识。

变分优化的数学基础是泛函分析理论。

<!-- more -->

## 引子

### 熵的最大化

#### 指数分布

> （[概统](http://opac.lib.ustc.edu.cn/opac/item.php?marc_no=636d454478364c3265587a376d37672f3977716141517a6a614e47374b49796b5251534c65594a356b50773d) 例4.32）设连续性随机变量 $X$ 在 $(0, \infty)$ 上取值，对其期望进行约束，考虑如下熵最大化问题：
> 
> $$
> \max_XH(X),\quad \text{s.t.}~\mathbb E[x]=\frac{1}{\lambda}
> $$

由熵的定义，原问题等价于：

$$
\begin{matrix}
\displaystyle \max_f & \displaystyle -\int_0^{+\infty}f(x)\ln f(x)\mathrm dx\\
\text{s.t.} & \displaystyle \int_0^{+\infty}f(x)\mathrm dx=1,\quad\int_{0}^{+\infty}xf(x)\mathrm dx=\frac{1}{\lambda}
\end{matrix}
$$

构造 $G(t) = H(f + tg)$，使用 Lagrange 乘子法，有：

$$
\begin{aligned}
\overline G(t)&=G(t)+c_0\left(\int_0^{+\infty}f(x)\mathrm dx-1\right)+c_1\left(\int_{0}^{+\infty}xf(x)\mathrm dx-\frac{1}{\lambda}\right)\\
\frac{\mathrm d \overline G}{\mathrm d t} &=\left(-\int_0^{+\infty}g(x)\ln(f(x)+tg(x))\mathrm dx-\int_0^{+\infty}g(x)\mathrm dx\right)\\
&\quad+c_0\int_{0}^{+\infty}g(x)\mathrm dx+c_1\int_{0}^{+\infty}xg(x)\mathrm dx\\
&= \int_0^{+\infty}g(x)(-\ln(f(x)+tg(x))+c_1x+c_0-1)\\
\left.\frac{\mathrm d \overline G}{\mathrm dt}\right|_{t=0}&=0\implies -\ln f(x)+c_1x+c_0-1=0\\
&\qquad \implies \boxed{f(x)=\lambda e^{-\lambda x}I_{(0,+\infty)}(x)}
\end{aligned}
$$

这是书上给出的证明形式，但是，其中有几个值得注意的问题：

- 
